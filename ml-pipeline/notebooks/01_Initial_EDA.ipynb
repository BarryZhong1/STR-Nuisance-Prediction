{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ” STR Nuisance Prediction - Scottsdale Data Analysis\n",
    "\n",
    "**Objective**: Explore Scottsdale's comprehensive STR and complaint datasets.\n",
    "\n",
    "**Data**: 9 Scottsdale public datasets loaded directly from Google Drive\n",
    "\n",
    "## ğŸ“Š What We'll Analyze:\n",
    "1. ğŸ  Licensed, unlicensed, and pending STR properties\n",
    "2. ğŸ“ EZ complaints and code violations  \n",
    "3. ğŸ‘® Police incidents, citations, and arrests\n",
    "4. ğŸ—ºï¸ Property parcel information\n",
    "5. ğŸ¯ STR nuisance prediction targets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"ğŸš€ STR Nuisance Prediction Analysis - Scottsdale\")\n",
    "print(f\"ğŸ“… Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"ğŸ“š Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¥ Load Scottsdale Data\n",
    "# Import the data loader\n",
    "sys.path.append('../src')\n",
    "\n",
    "try:\n",
    "    from data_processing.scottsdale_data_loader import ScottsdaleSTRDataLoader\n",
    "    print(\"âœ… Data loader imported successfully\")\n",
    "    \n",
    "    # Initialize and load all data (no setup needed - file IDs are pre-configured)\n",
    "    loader = ScottsdaleSTRDataLoader()\n",
    "    \n",
    "    print(\"\\nğŸ”„ Loading all 9 Scottsdale datasets...\")\n",
    "    print(\"â³ This will take a few minutes for the large files...\")\n",
    "    \n",
    "    # Load everything\n",
    "    datasets = loader.load_all_datasets()\n",
    "    \n",
    "    # Organize by category\n",
    "    categorized = loader.get_dataset_by_category()\n",
    "    \n",
    "    print(\"\\nğŸ‰ Data loading completed!\")\n",
    "    \nexcept ImportError as e:\n",
    "    print(f\"âŒ Could not import data loader: {e}\")\n",
    "    print(\"ğŸ“ Make sure you've created: ml-pipeline/src/data_processing/scottsdale_data_loader.py\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Extract Individual Datasets\n",
    "if 'datasets' in locals():\n",
    "    # STR Properties\n",
    "    licensed_strs = datasets.get('licensed_strs')\n",
    "    unlicensed_strs = datasets.get('unlicensed_strs')\n",
    "    pending_strs = datasets.get('pending_licences')\n",
    "    \n",
    "    # Complaints\n",
    "    ez_complaints = datasets.get('ez_complaints')\n",
    "    code_violations = datasets.get('code_violations')\n",
    "    \n",
    "    # Police Data\n",
    "    police_incidents = datasets.get('police_incidents')\n",
    "    police_citations = datasets.get('police_citations')\n",
    "    police_arrests = datasets.get('police_arrests')\n",
    "    \n",
    "    # Geographic\n",
    "    parcels = datasets.get('parcels')\n",
    "    \n",
    "    print(\"ğŸ“‹ DATASET SUMMARY\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Function to show dataset info\n",
    "    def show_dataset_info(df, name, emoji):\n",
    "        if df is not None:\n",
    "            print(f\"{emoji} {name}: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âŒ {name}: Failed to load\")\n",
    "            return False\n",
    "    \n",
    "    print(\"\\nğŸ  STR Properties:\")\n",
    "    licensed_loaded = show_dataset_info(licensed_strs, \"Licensed STRs\", \"âœ…\")\n",
    "    unlicensed_loaded = show_dataset_info(unlicensed_strs, \"Unlicensed STRs\", \"âœ…\")\n",
    "    pending_loaded = show_dataset_info(pending_strs, \"Pending Licences\", \"âœ…\")\n",
    "    \n",
    "    print(\"\\nğŸ“ Complaints & Violations:\")\n",
    "    complaints_loaded = show_dataset_info(ez_complaints, \"EZ Complaints\", \"âœ…\")\n",
    "    violations_loaded = show_dataset_info(code_violations, \"Code Violations\", \"âœ…\")\n",
    "    \n",
    "    print(\"\\nğŸ‘® Police Data:\")\n",
    "    incidents_loaded = show_dataset_info(police_incidents, \"Police Incidents\", \"âœ…\")\n",
    "    citations_loaded = show_dataset_info(police_citations, \"Police Citations\", \"âœ…\")\n",
    "    arrests_loaded = show_dataset_info(police_arrests, \"Police Arrests\", \"âœ…\")\n",
    "    \n",
    "    print(\"\\nğŸ—ºï¸ Geographic:\")\n",
    "    parcels_loaded = show_dataset_info(parcels, \"Property Parcels\", \"âœ…\")\n",
    "    \n",
    "    # Count successful loads\n",
    "    successful_loads = sum([\n",
    "        licensed_loaded, unlicensed_loaded, pending_loaded,\n",
    "        complaints_loaded, violations_loaded,\n",
    "        incidents_loaded, citations_loaded, arrests_loaded,\n",
    "        parcels_loaded\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Successfully loaded: {successful_loads}/9 datasets\")\n",
    "    \nelse:\n",
    "    print(\"âŒ Datasets not available - check data loading above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ  Examine Licensed STR Properties (Main Dataset)\n",
    "if licensed_strs is not None:\n",
    "    print(\"ğŸ  LICENSED STR PROPERTIES - DETAILED ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"ğŸ“Š Basic Info:\")\n",
    "    print(f\"   Total licensed properties: {len(licensed_strs):,}\")\n",
    "    print(f\"   Columns: {len(licensed_strs.columns)}\")\n",
    "    print(f\"   Memory usage: {licensed_strs.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Column Names and Types:\")\n",
    "    for i, (col, dtype) in enumerate(zip(licensed_strs.columns, licensed_strs.dtypes), 1):\n",
    "        non_null = licensed_strs[col].count()\n",
    "        null_pct = (len(licensed_strs) - non_null) / len(licensed_strs) * 100\n",
    "        print(f\"   {i:2d}. {col:<35} | {str(dtype):<15} | {null_pct:5.1f}% missing\")\n",
    "    \n",
    "    print(f\"\\nğŸ‘ï¸ Sample Data (first 5 rows):\")\n",
    "    display(licensed_strs.head())\n",
    "    \nelse:\n",
    "    print(\"âŒ Licensed STR data not available - this is our main dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ Examine EZ Complaints (Main Complaints Dataset)\n",
    "if ez_complaints is not None:\n",
    "    print(\"ğŸ“ EZ COMPLAINTS - DETAILED ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(f\"ğŸ“Š Basic Info:\")\n",
    "    print(f\"   Total complaints: {len(ez_complaints):,}\")\n",
    "    print(f\"   Columns: {len(ez_complaints.columns)}\")\n",
    "    print(f\"   Memory usage: {ez_complaints.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Column Names:\")\n",
    "    for i, col in enumerate(ez_complaints.columns, 1):\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nğŸ‘ï¸ Sample Complaints Data (first 3 rows):\")\n",
    "    display(ez_complaints.head(3))\n",
    "    \n",
    "    # Look for key columns\n",
    "    address_cols = [col for col in ez_complaints.columns if 'address' in col.lower()]\n",
    "    date_cols = [col for col in ez_complaints.columns if 'date' in col.lower()]\n",
    "    type_cols = [col for col in ez_complaints.columns if any(word in col.lower() for word in ['type', 'category', 'subject'])]\n",
    "    \n",
    "    print(f\"\\nğŸ” Key Columns Identified:\")\n",
    "    if address_cols:\n",
    "        print(f\"   ğŸ“ Address columns: {address_cols}\")\n",
    "    if date_cols:\n",
    "        print(f\"   ğŸ“… Date columns: {date_cols}\")\n",
    "    if type_cols:\n",
    "        print(f\"   ğŸ“‹ Type columns: {type_cols}\")\n",
    "        \nelse:\n",
    "    print(\"âŒ EZ Complaints data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”— Identify Data Linking Opportunities\n",
    "print(\"ğŸ”— DATA LINKING ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if licensed_strs is not None and ez_complaints is not None:\n",
    "    # Look for common columns\n",
    "    str_cols = set(licensed_strs.columns)\n",
    "    complaint_cols = set(ez_complaints.columns)\n",
    "    common_cols = str_cols.intersection(complaint_cols)\n",
    "    \n",
    "    print(f\"ğŸ“Š Column Analysis:\")\n",
    "    print(f\"   Licensed STR columns: {len(str_cols)}\")\n",
    "    print(f\"   EZ Complaints columns: {len(complaint_cols)}\")\n",
    "    print(f\"   Common columns: {len(common_cols)}\")\n",
    "    \n",
    "    if common_cols:\n",
    "        print(f\"\\nğŸ”— Common Columns for Linking:\")\n",
    "        for col in sorted(common_cols):\n",
    "            print(f\"   ğŸ“‹ {col}\")\n",
    "    \n",
    "    # Look for address-like columns in each\n",
    "    str_address_cols = [col for col in licensed_strs.columns if 'address' in col.lower()]\n",
    "    complaint_address_cols = [col for col in ez_complaints.columns if 'address' in col.lower()]\n",
    "    \n",
    "    print(f\"\\nğŸ“ Address Columns for Spatial Linking:\")\n",
    "    if str_address_cols:\n",
    "        print(f\"   ğŸ  Licensed STRs: {str_address_cols}\")\n",
    "    if complaint_address_cols:\n",
    "        print(f\"   ğŸ“ EZ Complaints: {complaint_address_cols}\")\n",
    "    \n",
    "    # Show sample addresses for comparison\n",
    "    if str_address_cols and complaint_address_cols:\n",
    "        print(f\"\\nğŸ” Sample Address Formats:\")\n",
    "        print(f\"   STR addresses:\")\n",
    "        for addr in licensed_strs[str_address_cols[0]].dropna().head(3):\n",
    "            print(f\"      {addr}\")\n",
    "        \n",
    "        print(f\"   Complaint addresses:\")\n",
    "        for addr in ez_complaints[complaint_address_cols[0]].dropna().head(3):\n",
    "            print(f\"      {addr}\")\n",
    "\nelse:\n",
    "    print(\"âŒ Cannot analyze linking - missing STR or complaints data\")\n",
    "\n",
    "print(f\"\\nâœ… Initial exploration completed!\")\n",
    "print(f\"ğŸ“ Next: Based on the column structure, we'll create the linking and target variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Next Steps\n",
    "\n",
    "Based on the data structure we discovered above:\n",
    "\n",
    "1. **ğŸ”— Data Linking Strategy**: Connect STR properties to complaints using address matching\n",
    "2. **ğŸ“Š Complaint Analysis**: Understand complaint patterns and frequencies  \n",
    "3. **ğŸ¯ Target Creation**: Define nuisance properties based on complaint history\n",
    "4. **ğŸ› ï¸ Feature Engineering**: Create predictive features from all 9 datasets\n",
    "5. **ğŸ¤– Model Development**: Build and validate prediction models\n",
    "\n",
    "## ğŸ“‹ What We Learned\n",
    "\n",
    "The comprehensive Scottsdale dataset provides:\n",
    "- **Complete STR landscape**: Licensed, unlicensed, and pending properties\n",
    "- **Multi-source complaints**: EZ system + code violations + police data\n",
    "- **Rich geographic context**: Parcel-level property information\n",
    "- **Temporal depth**: Historical patterns for trend analysis\n",
    "\n",
    "This foundation enables sophisticated nuisance prediction modeling! ğŸ›ï¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
