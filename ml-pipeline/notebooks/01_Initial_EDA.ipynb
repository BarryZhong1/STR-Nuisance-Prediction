{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ” STR Nuisance Prediction - Initial EDA\n",
    "\n",
    "**Objective**: Explore STR and complaint datasets to understand patterns and identify features for nuisance prediction.\n",
    "\n",
    "**Dataset Source**: Scottsdale public data from Google Drive\n",
    "\n",
    "## Analysis Goals:\n",
    "1. ğŸ“Š Understanding data structure and quality\n",
    "2. ğŸ” Identifying nuisance patterns and trends  \n",
    "3. ğŸ  Exploring relationships between properties and complaints\n",
    "4. ğŸ› ï¸ Feature engineering opportunities\n",
    "5. ğŸ¯ Target variable definition\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"ğŸ“š Libraries imported successfully!\")\n",
    "print(f\"ğŸ—“ï¸ Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"ğŸš€ Ready to analyze Scottsdale STR data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Load Scottsdale STR Data\n",
    "\n",
    "Loading all 9 datasets from Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project path to Python path\n",
    "project_root = os.path.abspath('../src')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import the Scottsdale data loader\n",
    "try:\n",
    "    from data_processing.scottsdale_data_loader import ScottsdaleSTRDataLoader\n",
    "    print(\"âœ… Scottsdale data loader imported successfully\")\nexcept ImportError as e:\n",
    "    print(f\"âŒ Error importing data loader: {e}\")\n",
    "    print(\"ğŸ“ Please create the scottsdale_data_loader.py file first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”— Initialize Data Loader and Set Up File Links\n",
    "loader = ScottsdaleSTRDataLoader()\n",
    "\n",
    "# Set up all your Google Drive file links\n",
    "file_links = {\n",
    "    'unlicensed_strs': 'https://drive.google.com/file/d/12mlo9JtfIUfOz3CxJVCEIgVIEZKGyQ6X/view?usp=drive_link',\n",
    "    'ez_complaints': 'https://drive.google.com/file/d/1UDbXLlVdikJGFyVgOxLExYWFqe3ADcSj/view?usp=drive_link',\n",
    "    'police_incidents': 'https://drive.google.com/file/d/1PF_cAutvvEMiAmEHzH2Qbljz73k75x0R/view?usp=drive_link',\n",
    "    'police_citations': 'https://drive.google.com/file/d/1PQW90VjQsbYXxhOlpRXKM2MRyEbmOL0N/view?usp=drive_link',\n",
    "    'police_arrests': 'https://drive.google.com/file/d/118W8cbYAnEgzPwy1I_cVuqoHLpoMz9UG/view?usp=drive_link',\n",
    "    'code_violations': 'https://drive.google.com/file/d/1vUJ-HXU1RGb9AOvn0jAaaSkiYq4ICITs/view?usp=drive_link',\n",
    "    'pending_licences': 'https://drive.google.com/file/d/1ybALd2DDYsdP6VgeLfnioo1kKSYt_xRR/view?usp=drive_link',\n",
    "    'parcels': 'https://drive.google.com/file/d/19PPloUcM2FHxxQP17s4091aaLZjp4juB/view?usp=drive_link',\n",
    "    'licensed_strs': 'https://drive.google.com/file/d/16-lg-5fj-dttKUgwWTbzo0wDH4lCvV-t/view?usp=drive_link'\n",
    "}\n",
    "\n",
    "print(\"ğŸ”— Setting up Google Drive connections...\")\n",
    "loader.setup_file_links(file_links)\n",
    "loader.print_file_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¥ Load All Datasets\n",
    "print(\"ğŸ“¥ Loading all Scottsdale STR datasets...\")\n",
    "print(\"â³ This may take a few minutes for large files...\")\n",
    "\n",
    "# Load all datasets\n",
    "datasets = loader.load_all_datasets()\n",
    "\n",
    "# Get organized datasets by category\n",
    "categorized = loader.get_dataset_by_category()\n",
    "\n",
    "# Extract main datasets for analysis\n",
    "str_properties = categorized['str_properties']\n",
    "complaints_data = categorized['complaints']\n",
    "police_data = categorized['police']\n",
    "geographic_data = categorized['geographic']\n",
    "\n",
    "# Main datasets for EDA\n",
    "licensed_strs = str_properties['licensed']           # Main STR properties\n",
    "unlicensed_strs = str_properties['unlicensed']       # Unlicensed properties\n",
    "pending_strs = str_properties['pending']             # Pending applications\n",
    "\n",
    "ez_complaints = complaints_data['ez_complaints']      # Main complaints system\n",
    "code_violations = complaints_data['code_violations']  # Code enforcement\n",
    "\n",
    "police_incidents = police_data['incidents']          # Police incidents\n",
    "police_citations = police_data['citations']          # Citations issued\n",
    "police_arrests = police_data['arrests']              # Arrests made\n",
    "\n",
    "parcels = geographic_data['parcels']                 # Property details\n",
    "\n",
    "print(\"\\nâœ… Data loading completed!\")\n",
    "print(\"ğŸ¯ Ready for comprehensive STR nuisance analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Dataset Overview\n",
    "\n",
    "Let's examine what we have in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‹ Dataset Summary\n",
    "def print_dataset_summary(df, name):\n",
    "    \"\"\"Print summary of a dataset\"\"\"\n",
    "    if df is not None:\n",
    "        print(f\"ğŸ“Š {name}:\")\n",
    "        print(f\"   Rows: {df.shape[0]:,}\")\n",
    "        print(f\"   Columns: {df.shape[1]}\")\n",
    "        print(f\"   Memory: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "        print(f\"   Columns: {list(df.columns)[:5]}{'...' if len(df.columns) > 5 else ''}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"âŒ {name}: Not loaded\")\n",
    "        print()\n",
    "\n",
    "print(\"ğŸ“‹ DATASET SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\nğŸ  STR Properties:\")\n",
    "print_dataset_summary(licensed_strs, \"Licensed STRs\")\n",
    "print_dataset_summary(unlicensed_strs, \"Unlicensed STRs\")\n",
    "print_dataset_summary(pending_strs, \"Pending Licences\")\n",
    "\n",
    "print(\"\\nğŸ“ Complaints & Violations:\")\n",
    "print_dataset_summary(ez_complaints, \"EZ Complaints\")\n",
    "print_dataset_summary(code_violations, \"Code Violations\")\n",
    "\n",
    "print(\"\\nğŸ‘® Police Data:\")\n",
    "print_dataset_summary(police_incidents, \"Police Incidents\")\n",
    "print_dataset_summary(police_citations, \"Police Citations\")\n",
    "print_dataset_summary(police_arrests, \"Police Arrests\")\n",
    "\n",
    "print(\"\\nğŸ—ºï¸ Geographic Data:\")\n",
    "print_dataset_summary(parcels, \"Parcels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ  STR Properties Analysis\n",
    "\n",
    "Let's start with the core STR properties data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ  Licensed STR Analysis\n",
    "if licensed_strs is not None:\n",
    "    print(\"ğŸ  LICENSED STR PROPERTIES ANALYSIS\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    print(f\"ğŸ“Š Dataset Overview:\")\n",
    "    print(f\"   Total licensed STRs: {len(licensed_strs):,}\")\n",
    "    print(f\"   Columns: {len(licensed_strs.columns)}\")\n",
    "    \n",
    "    # Show column names and types\n",
    "    print(f\"\\nğŸ“‹ Column Information:\")\n",
    "    for i, (col, dtype) in enumerate(zip(licensed_strs.columns, licensed_strs.dtypes), 1):\n",
    "        non_null = licensed_strs[col].count()\n",
    "        print(f\"   {i:2d}. {col:30} | {str(dtype):15} | {non_null:,} non-null\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"\\nğŸ‘ï¸  Sample Licensed STRs:\")\n",
    "    display(licensed_strs.head(3))\n",
    "    \n",
    "    # Basic statistics for numeric columns\n",
    "    numeric_cols = licensed_strs.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nğŸ“ˆ Numeric Columns Statistics:\")\n",
    "        display(licensed_strs[numeric_cols].describe())\nelse:\n",
    "    print(\"âŒ Licensed STR data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ EZ Complaints Analysis\n",
    "if ez_complaints is not None:\n",
    "    print(\"ğŸ“ EZ COMPLAINTS ANALYSIS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    print(f\"ğŸ“Š Dataset Overview:\")\n",
    "    print(f\"   Total complaints: {len(ez_complaints):,}\")\n",
    "    print(f\"   Columns: {len(ez_complaints.columns)}\")\n",
    "    \n",
    "    # Show column names\n",
    "    print(f\"\\nğŸ“‹ Complaint Columns:\")\n",
    "    for i, col in enumerate(ez_complaints.columns, 1):\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"\\nğŸ‘ï¸  Sample Complaints:\")\n",
    "    display(ez_complaints.head(3))\n",
    "    \n",
    "    # Look for date columns\n",
    "    date_cols = [col for col in ez_complaints.columns if 'date' in col.lower()]\n",
    "    if date_cols:\n",
    "        print(f\"\\nğŸ“… Date columns found: {date_cols}\")\n",
    "    \n",
    "    # Look for complaint type columns\n",
    "    type_cols = [col for col in ez_complaints.columns \n",
    "                if any(word in col.lower() for word in ['type', 'category', 'nature'])]\n",
    "    if type_cols:\n",
    "        print(f\"ğŸ“‹ Type columns found: {type_cols}\")\nelse:\n",
    "    print(\"âŒ EZ Complaints data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— Data Relationships\n",
    "\n",
    "Let's explore how we can connect the different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”— Find Common Columns for Linking Datasets\n",
    "print(\"ğŸ”— DATASET LINKING ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Function to find common columns\n",
    "def find_common_columns(df1, df2, name1, name2):\n",
    "    if df1 is not None and df2 is not None:\n",
    "        common = set(df1.columns).intersection(set(df2.columns))\n",
    "        if common:\n",
    "            print(f\"\\nğŸ”— {name1} â†” {name2}:\")\n",
    "            for col in common:\n",
    "                print(f\"   ğŸ“‹ {col}\")\n",
    "        return common\n",
    "    return set()\n",
    "\n",
    "# Check key relationships\n",
    "print(\"ğŸ“Š Looking for linkage columns...\")\n",
    "\n",
    "# STR properties to complaints\n",
    "if licensed_strs is not None and ez_complaints is not None:\n",
    "    common = find_common_columns(licensed_strs, ez_complaints, \"Licensed STRs\", \"EZ Complaints\")\n",
    "\n",
    "# STR properties to parcels\n",
    "if licensed_strs is not None and parcels is not None:\n",
    "    common = find_common_columns(licensed_strs, parcels, \"Licensed STRs\", \"Parcels\")\n",
    "\n",
    "# Complaints to police data\n",
    "if ez_complaints is not None and police_incidents is not None:\n",
    "    common = find_common_columns(ez_complaints, police_incidents, \"EZ Complaints\", \"Police Incidents\")\n",
    "\n",
    "# Look for address-like columns\n",
    "print(f\"\\nğŸ  Address-like columns for spatial linking:\")\n",
    "for name, df in [('Licensed STRs', licensed_strs), ('EZ Complaints', ez_complaints), \n",
    "                ('Parcels', parcels), ('Police Incidents', police_incidents)]:\n",
    "    if df is not None:\n",
    "        addr_cols = [col for col in df.columns if 'address' in col.lower() or 'location' in col.lower()]\n",
    "        if addr_cols:\n",
    "            print(f\"   ğŸ“ {name}: {addr_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Target Variable Creation\n",
    "\n",
    "Based on the data structure, let's create our nuisance prediction targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Create Target Variables\n",
    "print(\"ğŸ¯ TARGET VARIABLE CREATION\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# This will be customized based on what we find in the actual data structure\n",
    "print(\"ğŸ“ Next steps after examining the data:\")\n",
    "print(\"   1. Identify address/location matching strategy\")\n",
    "print(\"   2. Link STR properties to complaints\")\n",
    "print(\"   3. Count complaints per property\")\n",
    "print(\"   4. Define nuisance thresholds\")\n",
    "print(\"   5. Create binary/categorical targets\")\n",
    "\n",
    "print(f\"\\nâœ… Data loading and initial exploration completed!\")\n",
    "print(f\"ğŸ“Š Ready for detailed feature engineering based on actual data structure\")\n",
    "print(f\"ğŸ—“ï¸ Analysis timestamp: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Next Steps\n",
    "\n",
    "Based on this initial exploration, we'll proceed with:\n",
    "\n",
    "1. **ğŸ”— Data Linking** - Connect STRs to complaints using address matching\n",
    "2. **ğŸ¯ Target Definition** - Define nuisance based on complaint patterns\n",
    "3. **ğŸ› ï¸ Feature Engineering** - Create predictive features from all datasets\n",
    "4. **ğŸ¤– Model Development** - Build and train prediction models\n",
    "5. **âœ… Validation** - Test model performance\n",
    "\n",
    "The comprehensive Scottsdale dataset provides excellent opportunities for:\n",
    "- Multi-source complaint analysis (EZ + Code + Police)\n",
    "- Licensed vs unlicensed property comparison\n",
    "- Geographic risk assessment using parcels\n",
    "- Temporal pattern analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
